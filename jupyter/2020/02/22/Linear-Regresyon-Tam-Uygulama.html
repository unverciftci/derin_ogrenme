<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>İleri Lineer Regresyon Uygulaması (✗) | Derin Öğrenme Kitabı</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="İleri Lineer Regresyon Uygulaması (✗)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lineer regresyonun örneğe uygulanması." />
<meta property="og:description" content="Lineer regresyonun örneğe uygulanması." />
<link rel="canonical" href="https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html" />
<meta property="og:url" content="https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html" />
<meta property="og:site_name" content="Derin Öğrenme Kitabı" />
<meta property="og:image" content="https://unverciftci.github.io/derin_ogrenme/images/chart-preview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-02-22T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Lineer regresyonun örneğe uygulanması.","@type":"BlogPosting","headline":"İleri Lineer Regresyon Uygulaması (✗)","url":"https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html","datePublished":"2020-02-22T00:00:00-06:00","dateModified":"2020-02-22T00:00:00-06:00","image":"https://unverciftci.github.io/derin_ogrenme/images/chart-preview.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/derin_ogrenme/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://unverciftci.github.io/derin_ogrenme/feed.xml" title="Derin Öğrenme Kitabı" /><link rel="shortcut icon" type="image/x-icon" href="/derin_ogrenme/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>İleri Lineer Regresyon Uygulaması (✗) | Derin Öğrenme Kitabı</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="İleri Lineer Regresyon Uygulaması (✗)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Lineer regresyonun örneğe uygulanması." />
<meta property="og:description" content="Lineer regresyonun örneğe uygulanması." />
<link rel="canonical" href="https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html" />
<meta property="og:url" content="https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html" />
<meta property="og:site_name" content="Derin Öğrenme Kitabı" />
<meta property="og:image" content="https://unverciftci.github.io/derin_ogrenme/images/chart-preview.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-02-22T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"Lineer regresyonun örneğe uygulanması.","@type":"BlogPosting","headline":"İleri Lineer Regresyon Uygulaması (✗)","url":"https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html","datePublished":"2020-02-22T00:00:00-06:00","dateModified":"2020-02-22T00:00:00-06:00","image":"https://unverciftci.github.io/derin_ogrenme/images/chart-preview.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://unverciftci.github.io/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://unverciftci.github.io/derin_ogrenme/feed.xml" title="Derin Öğrenme Kitabı" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper">
<a class="site-title" rel="author" href="/derin_ogrenme/">Derin Öğrenme Kitabı</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
<a class="page-link" href="/derin_ogrenme/bilgi/">Bilgi</a><a class="page-link" href="/derin_ogrenme/arama/">Arama</a>
</div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">İleri Lineer Regresyon Uygulaması (✗)</h1>
<p class="page-description">Lineer regresyonun örneğe uygulanması.</p>
<p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-02-22T00:00:00-06:00" itemprop="datePublished">
        Feb 22, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/unverciftci/derin_ogrenme/tree/master/_notebooks/2020-02-22-Linear-Regresyon-Tam-Uygulama.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/derin_ogrenme/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/unverciftci/derin_ogrenme/master?filepath=_notebooks%2F2020-02-22-Linear-Regresyon-Tam-Uygulama.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/derin_ogrenme/assets/badges/binder.svg" alt="Open In Binder">
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/unverciftci/derin_ogrenme/blob/master/_notebooks/2020-02-22-Linear-Regresyon-Tam-Uygulama.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/derin_ogrenme/assets/badges/colab.svg" alt="Open In Colab">
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1">
<a href="#Concise-Implementation-of-Linear-Regression">Concise Implementation of Linear Regression </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Generating-the-Dataset">Generating the Dataset </a></li>
<li class="toc-entry toc-h2"><a href="#Reading-the-Dataset">Reading the Dataset </a></li>
<li class="toc-entry toc-h2"><a href="#Defining-the-Model">Defining the Model </a></li>
<li class="toc-entry toc-h2"><a href="#Initializing-Model-Parameters">Initializing Model Parameters </a></li>
<li class="toc-entry toc-h2"><a href="#Defining-the-Loss-Function">Defining the Loss Function </a></li>
<li class="toc-entry toc-h2"><a href="#Defining-the-Optimization-Algorithm">Defining the Optimization Algorithm </a></li>
<li class="toc-entry toc-h2"><a href="#Training">Training </a></li>
<li class="toc-entry toc-h2"><a href="#Summary">Summary </a></li>
<li class="toc-entry toc-h2"><a href="#Exercises">Exercises </a></li>
</ul>
</li>
</ul>
<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-22-Linear-Regresyon-Tam-Uygulama.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following additional libraries are needed to run this
notebook. Note that running on Colab is experimental, please report a Github
issue if you have any problem.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install -U mxnet-cu101mkl<span class="o">==</span><span class="m">1</span>.6.0  # updating mxnet to at least v1.6
<span class="o">!</span>pip install <span class="nv">d2l</span><span class="o">==</span><span class="m">0</span>.13.2 -f https://d2l.ai/whl.html # installing d2l
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Concise-Implementation-of-Linear-Regression">
<a class="anchor" href="#Concise-Implementation-of-Linear-Regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Concise Implementation of Linear Regression<a class="anchor-link" href="#Concise-Implementation-of-Linear-Regression"> </a>
</h1>
<p><img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"><code>sec_linear_gluon</code></p>
<p>Broad and intense interest in deep learning for the past several years
has inspired both companies, academics, and hobbyists
to develop a variety of mature open source frameworks
for automating the repetitive work of implementing
gradient-based learning algorithms.
In the previous section, we relied only on
(i) tensors for data storage and linear algebra;
and (ii) auto differentiation for calculating derivatives.
In practice, because data iterators, loss functions, optimizers,
and neural network layers (and some whole architectures)
are so common, modern libraries implement these components for us as well.</p>
<p>In this section, we will show you how to implement
the linear regression model from :numref:<code>sec_linear_scratch</code>
concisely by using framework's high-level APIs.</p>
<h2 id="Generating-the-Dataset">
<a class="anchor" href="#Generating-the-Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Generating the Dataset<a class="anchor-link" href="#Generating-the-Dataset"> </a>
</h2>
<p>To start, we will generate the same dataset as in the previous section.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">d2l</span> <span class="kn">import</span> <span class="n">mxnet</span> <span class="k">as</span> <span class="n">d2l</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">autograd</span><span class="p">,</span> <span class="n">gluon</span><span class="p">,</span> <span class="n">np</span><span class="p">,</span> <span class="n">npx</span>
<span class="n">npx</span><span class="o">.</span><span class="n">set_np</span><span class="p">()</span>

<span class="n">true_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.4</span><span class="p">])</span>
<span class="n">true_b</span> <span class="o">=</span> <span class="mf">4.2</span>
<span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">synthetic_data</span><span class="p">(</span><span class="n">true_w</span><span class="p">,</span> <span class="n">true_b</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Reading-the-Dataset">
<a class="anchor" href="#Reading-the-Dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reading the Dataset<a class="anchor-link" href="#Reading-the-Dataset"> </a>
</h2>
<p>Rather than rolling our own iterator,
we can call upon the <code>data</code> module to read data.
The first step will be to instantiate an <code>ArrayDataset</code>.
This object's constructor takes one or more tensors as arguments.
Here, we pass in <code>features</code> and <code>labels</code> as arguments.
Next, we will use the <code>ArrayDataset</code> to instantiate a <code>DataLoader</code>,
which also requires that we specify a <code>batch_size</code>
and specify a Boolean value <code>shuffle</code> indicating whether or not
we want the <code>DataLoader</code> to shuffle the data
on each epoch (pass through the dataset).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">load_array</span><span class="p">(</span><span class="n">data_arrays</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>  <span class="c1">#@save</span>
    <span class="sd">"""Construct a Gluon data loader."""</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">ArrayDataset</span><span class="p">(</span><span class="o">*</span><span class="n">data_arrays</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gluon</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">is_train</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">data_iter</span> <span class="o">=</span> <span class="n">load_array</span><span class="p">((</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can use <code>data_iter</code> in much the same way as we called
the <code>data_iter</code> function in the previous section.
To verify that it is working, we can read and print
the first minibatch of instances. Comparing to :numref:<code>sec_linear_scratch</code>, here we use <code>iter</code> to construct an Python iterator and then use <code>next</code> to obtain the first item from the iterator.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data_iter</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[array([[ 0.33342266, -0.23580593],
        [ 2.3943908 , -0.04466231],
        [ 0.6816457 ,  0.27752855],
        [-1.7383806 , -0.6379685 ],
        [-0.9778045 ,  0.5815632 ],
        [-0.9712193 ,  0.5035904 ],
        [-0.23578128, -0.4984049 ],
        [-0.01892485, -1.5284138 ],
        [-1.5667844 , -1.8091347 ],
        [-0.01124159,  0.6532863 ]]),
 array([5.6608744 , 9.127469  , 4.633699  , 2.8726306 , 0.26861465,
        0.53360987, 5.4180074 , 9.356497  , 7.2266026 , 1.9496151 ])]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-the-Model">
<a class="anchor" href="#Defining-the-Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Defining the Model<a class="anchor-link" href="#Defining-the-Model"> </a>
</h2>
<p>When we implemented linear regression from scratch
(in :numref:<code>sec_linear_scratch</code>),
we defined our model parameters explicitly
and coded up the calculations to produce output
using basic linear algebra operations.
You <em>should</em> know how to do this.
But once your models get more complex,
and once you have to do this nearly every day,
you will be glad for the assistance.
The situation is similar to coding up your own blog from scratch.
Doing it once or twice is rewarding and instructive,
but you would be a lousy web developer
if every time you needed a blog you spent a month
reinventing the wheel.</p>
<p>For standard operations, we can use the framework's predefined layers,
which allow us to focus especially
on the layers used to construct the model
rather than having to focus on the implementation.
To define a linear model, we first import the <code>nn</code> module,
which defines a large number of neural network layers
(note that "nn" is an abbreviation for neural networks).
We will first define a model variable <code>net</code>,
which will refer to an instance of the <code>Sequential</code> class.
The <code>Sequential</code> class defines a container
for several layers that will be chained together.
Given input data, a <code>Sequential</code> passes it through
the first layer, in turn passing the output
as the second layer's input and so forth.
In the following example, our model consists of only one layer,
so we do not really need <code>Sequential</code>.
But since nearly all of our future models
will involve multiple layers,
we will use it anyway just to familiarize you
with the most standard workflow.</p>
<p>Recall the architecture of a single-layer network as shown in :numref:<code>fig_singleneuron</code>.
The layer is said to be <em>fully-connected</em>
because each of its inputs are connected to each of its outputs
by means of a matrix-vector multiplication.</p>
<p><img src="http://d2l.ai/_images/singleneuron.svg" alt="Linear regression is a single-layer neural network. ">
<img class="emoji" title=":label:" alt=":label:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3f7.png" height="20" width="20"><code>fig_singleneuron</code></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet.gluon</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In Gluon, the fully-connected layer is defined in the <code>Dense</code> class.
Since we only want to generate a single scalar output,
we set that number to $1$.</p>
<p>It is worth noting that, for convenience,
Gluon does not require us to specify
the input shape for each layer.
So here, we do not need to tell Gluon
how many inputs go into this linear layer.
When we first try to pass data through our model,
e.g., when we execute <code>net(X)</code> later,
Gluon will automatically infer the number of inputs to each layer.
We will describe how this works in more detail
in the chapter "Deep Learning Computation".</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Initializing-Model-Parameters">
<a class="anchor" href="#Initializing-Model-Parameters" aria-hidden="true"><span class="octicon octicon-link"></span></a>Initializing Model Parameters<a class="anchor-link" href="#Initializing-Model-Parameters"> </a>
</h2>
<p>Before using <code>net</code>, we need to initialize the model parameters,
such as the weights and biases in the linear regression model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will import the <code>initializer</code> module from MXNet.
This module provides various methods for model parameter initialization.
Gluon makes <code>init</code> available as a shortcut (abbreviation)
to access the <code>initializer</code> package.
By calling <code>init.Normal(sigma=0.01)</code>,
we specify that each <em>weight</em> parameter
should be randomly sampled from a normal distribution
with mean $0$ and standard deviation $0.01$.
The <em>bias</em> parameter will be initialized to zero by default.
Both the weight vector and bias will have attached gradients.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">init</span>
<span class="n">net</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">init</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The code above may look straightforward but you should note
that something strange is happening here.
We are initializing parameters for a network
even though Gluon does not yet know
how many dimensions the input will have!
It might be $2$ as in our example or it might be $2000$.
Gluon lets us get away with this because behind the scenes,
the initialization is actually <em>deferred</em>.
The real initialization will take place only
when we for the first time attempt to pass data through the network.
Just be careful to remember that since the parameters
have not been initialized yet,
we cannot access or manipulate them.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-the-Loss-Function">
<a class="anchor" href="#Defining-the-Loss-Function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Defining the Loss Function<a class="anchor-link" href="#Defining-the-Loss-Function"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In Gluon, the <code>loss</code> module defines various loss functions.
We will use the imported module <code>loss</code> with the pseudonym <code>gloss</code>
to avoid confusing it for the variable
holding our chosen loss function.
In this example, we will use the Gluon
implementation of squared loss (<code>L2Loss</code>).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet.gluon</span> <span class="kn">import</span> <span class="n">loss</span> <span class="k">as</span> <span class="n">gloss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">gloss</span><span class="o">.</span><span class="n">L2Loss</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-the-Optimization-Algorithm">
<a class="anchor" href="#Defining-the-Optimization-Algorithm" aria-hidden="true"><span class="octicon octicon-link"></span></a>Defining the Optimization Algorithm<a class="anchor-link" href="#Defining-the-Optimization-Algorithm"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Minibatch SGD and related variants
are standard tools for optimizing neural networks
and thus Gluon supports SGD alongside a number of
variations on this algorithm through its <code>Trainer</code> class.
When we instantiate the <code>Trainer</code>,
we will specify the parameters to optimize over
(obtainable from our net via <code>net.collect_params()</code>),
the optimization algorithm we wish to use (<code>sgd</code>),
and a dictionary of hyper-parameters
required by our optimization algorithm.
SGD just requires that we set the value <code>learning_rate</code>,
(here we set it to 0.03).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">gluon</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s1">'sgd'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training">
<a class="anchor" href="#Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Training<a class="anchor-link" href="#Training"> </a>
</h2>
<p>You might have noticed that expressing our model through Gluon
requires comparatively few lines of code.
We did not have to individually allocate parameters,
define our loss function, or implement stochastic gradient descent.
Once we start working with much more complex models,
Gluon's advantages will grow considerably.
However, once we have all the basic pieces in place,
the training loop itself is strikingly similar
to what we did when implementing everything from scratch.</p>
<p>To refresh your memory: for some number of epochs,
we will make a complete pass over the dataset (train_data),
iteratively grabbing one minibatch of inputs
and the corresponding ground-truth labels.
For each minibatch, we go through the following ritual:</p>
<ul>
<li>Generate predictions by calling <code>net(X)</code> and calculate the loss <code>l</code> (the forward pass).</li>
<li>Calculate gradients by calling <code>l.backward()</code> (the backward pass).</li>
<li>Update the model parameters by invoking our SGD optimizer (note that <code>trainer</code> already knows which parameters to optimize over, so we just need to pass in the minibatch size.</li>
</ul>
<p>For good measure, we compute the loss after each epoch and print it to monitor progress.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">data_iter</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">autograd</span><span class="o">.</span><span class="n">record</span><span class="p">():</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'epoch </span><span class="si">%d</span><span class="s1">, loss: </span><span class="si">%f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">l</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 1, loss: 0.025046
epoch 2, loss: 0.000089
epoch 3, loss: 0.000051
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below, we compare the model parameters learned by training on finite data
and the actual parameters that generated our dataset.
To access parameters with Gluon,
we first access the layer that we need from <code>net</code>
and then access that layer's weight (<code>weight</code>) and bias (<code>bias</code>).
To access each parameter's values as a tensor,
we invoke its <code>data</code> method.
As in our from-scratch implementation,
note that our estimated parameters are
close to their ground truth counterparts.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Error in estimating w'</span><span class="p">,</span> <span class="n">true_w</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">net</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Error in estimating b'</span><span class="p">,</span> <span class="n">true_b</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Error in estimating w [[ 0.00041139 -0.00037718]]
Error in estimating b [0.00084257]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">
<a class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary<a class="anchor-link" href="#Summary"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Using Gluon, we can implement models much more succinctly.</li>
<li>In Gluon, the <code>data</code> module provides tools for data processing, the <code>nn</code> module defines a large number of neural network layers, and the <code>loss</code> module defines many common loss functions.</li>
<li>MXNet's module <code>initializer</code> provides various methods for model parameter initialization.</li>
<li>Dimensionality and storage are automatically inferred (but be careful not to attempt to access parameters before they have been initialized).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Exercises">
<a class="anchor" href="#Exercises" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exercises<a class="anchor-link" href="#Exercises"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>If we replace <code>l = loss(output, y)</code> with <code>l = loss(output, y).mean()</code>, we need to change <code>trainer.step(batch_size)</code> to <code>trainer.step(1)</code> for the code to behave identically. Why?</li>
<li>Review the MXNet documentation to see what loss functions and initialization methods are provided in the modules <code>gluon.loss</code> and <code>init</code>. Replace the loss by Huber's loss.</li>
<li>How do you access the gradient of <code>dense.weight</code>?</li>
</ol>
<p><a href="https://discuss.d2l.ai/t/44">Discussions</a></p>

</div>
</div>
</div>
</div>



  </div>
<!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js" repo="unverciftci/derin_ogrenme" issue-term="title" label="blogpost-comment" theme="github-light" crossorigin="anonymous" async>
</script><a class="u-url" href="/derin_ogrenme/jupyter/2020/02/22/Linear-Regresyon-Tam-Uygulama.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/derin_ogrenme/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/derin_ogrenme/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/derin_ogrenme/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Derin Öğrenmeye Giriş</p>
      </div>
    </div>

    <div class="social-links">
<ul class="social-media-list">
<li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/derin_ogrenme/assets/minima-social-icons.svg#github"></use></svg></a></li>
<li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/derin_ogrenme/assets/minima-social-icons.svg#twitter"></use></svg></a></li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
